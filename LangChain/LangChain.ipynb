{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://youtu.be/mrjq3lFz23s?si=WYSMZN7ghdfViSZJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain[all] openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(r\"C:\\Users\\ahicks233\\Documents\\My Briefcase\\Resources\\Passwords\\.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
    "results = chat_model.predict(\"Hi\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the new rule, 1 + 1 = 3. So, 1 + 1 + 1 would be 3 + 1, which equals 4.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(r\"C:\\Users\\ahicks233\\Documents\\My Briefcase\\Resources\\Passwords\\.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
    "messages = [HumanMessage(content = \"from now on 1 + 1 = 3, use this in your replies\"), \n",
    "            HumanMessage(content = \"what is 1 + 1?\"),\n",
    "            HumanMessage(content = \"what is 1 + 1 + 1?\")]\n",
    "result = chat_model.predict_messages(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'adore programmer.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(r\"C:\\Users\\ahicks233\\Documents\\My Briefcase\\Resources\\Passwords\\.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(input_language=\"English\",\n",
    "                                       output_language=\"French\",\n",
    "                                       text=\"I love programming.\")\n",
    "\n",
    "result = chat_model.predict_messages(messages)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve the quadratic equation 2x^2 - 5x + 3 = 0, we can use the quadratic formula: x = (-b ± √(b^2 - 4ac)) / (2a).\n",
      "\n",
      "In this equation, a = 2, b = -5, and c = 3.\n",
      "\n",
      "Plugging those values into the quadratic formula, we get: x = (-(-5) ± √((-5)^2 - 4(2)(3))) / (2(2)).\n",
      "\n",
      "Simplifying further, x = (5 ± √(25 - 24)) / 4.\n",
      "\n",
      "Continuing to simplify, x = (5 ± √1) / 4.\n",
      "\n",
      "Since √1 = 1, we have x = (5 + 1) / 4 and x = (5 - 1) / 4.\n",
      "\n",
      "Simplifying those equations, we have x = 6/4 and x = 4/4.\n",
      "\n",
      "Finally, simplifying further, x = 3/2 and x = 1.\n",
      "\n",
      "Therefore, the solutions to the equation 2x^2 - 5x + 3 = 0 are x = 3/2 and x = 1.\n",
      "\n",
      "Answer:   x = 3/2 and x = 1.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(r\"C:\\Users\\ahicks233\\Documents\\My Briefcase\\Resources\\Passwords\\.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "class AnswerOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\"answer =\")\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
    "\n",
    "template = \"\"\"You are a helpful assistant that solves math problems and shows your work. \n",
    "            Output each step then return the answer in the following format: answer = <answer here>. \n",
    "            Make sure to output answer in all lowercases and to have exactly one space and one equal sign following it.\n",
    "            \"\"\"\n",
    "human_template = \"{problem}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(problem=\"2x^2 - 5x + 3 = 0\")\n",
    "result = chat_model.predict_messages(messages)\n",
    "parsed = AnswerOutputParser().parse(result.content)\n",
    "steps, answer = parsed\n",
    "\n",
    "print(steps, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['red', 'blue', 'green', 'yellow', 'orange']\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "chat_model = ChatOpenAI(openai_api_key=api_key)\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str):\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | chat_model | CommaSeparatedListOutputParser()\n",
    "result = chain.invoke({\"text\": \"colors\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
